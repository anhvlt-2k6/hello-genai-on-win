# Configuration for the LLM service
LLM_BASE_URL=http://model-runner.docker.internal/engines/llama.cpp/v1

# Configuration for the model to use. Recommended to use a basic model for testing before asking real questions.
# You can find available models at https://hub.docker.com/u/ai
LLM_MODEL_NAME=ai/smollm2